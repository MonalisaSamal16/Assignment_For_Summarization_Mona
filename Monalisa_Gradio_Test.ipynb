{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jKpFdwRihN8ZRuhfbp9XLI4KZQUpgtE1","timestamp":1761666320902}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ASSIGNMENT GOES BELOW -"],"metadata":{"id":"2uRw9YNZfP13"}},{"cell_type":"code","source":["# --- Colab one-cell app: HF Summarizer + TTS + Export + Dark/Light toggle ---\n","# If you're in Colab, this should \"just work\".\n","\n","!pip -q install -U transformers accelerate sentencepiece gradio gTTS pydub\n","\n","import os, re, json, uuid, zipfile, datetime, tempfile, shutil\n","from pathlib import Path\n","import gradio as gr\n","from transformers import pipeline\n","from gtts import gTTS\n","\n","# ========== CONFIG ==========\n","HF_TOKEN = \"HFACE_TOKEN\"  # <-- uses your provided token, no new resources created\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN\n","os.environ[\"HF_TOKEN\"] = HF_TOKEN\n","# ============================\n","\n","# Global state for the loaded pipeline\n","_SUMMARIZER = None\n","_CURRENT_MODEL_ID = None\n","\n","def _load_model(model_id: str):\n","    \"\"\"\n","    Load (or reload) a summarization pipeline from Hugging Face Hub.\n","    We pass token via env var so nothing is created server-side.\n","    \"\"\"\n","    global _SUMMARIZER, _CURRENT_MODEL_ID\n","    if not model_id or \"/\" not in model_id:\n","        raise gr.Error(\"Please provide a valid Hugging Face model ID (e.g., 'facebook/bart-large-cnn').\")\n","    try:\n","        # device_map=\"auto\" will use GPU if available\n","        _SUMMARIZER = pipeline(\n","            \"summarization\",\n","            model=model_id,\n","            tokenizer=model_id,\n","            device_map=\"auto\",\n","            # transformers>=4.41 reads token from env; passing explicit token is also okay:\n","            # token=os.environ.get(\"HF_TOKEN\")\n","        )\n","        _CURRENT_MODEL_ID = model_id\n","        return gr.update(value=f\"‚úÖ Loaded model: `{model_id}`\"), f\"Model loaded: {model_id}\"\n","    except Exception as e:\n","        _SUMMARIZER = None\n","        _CURRENT_MODEL_ID = None\n","        raise gr.Error(f\"Model load failed: {e}\")\n","\n","def _chunk_text_words(text: str, max_words=800):\n","    \"\"\"\n","    Naive chunker: splits long text into ~max_words pieces to avoid hitting model limits.\n","    Keeps paragraphs together where possible.\n","    \"\"\"\n","    if len(text.split()) <= max_words:\n","        return [text]\n","    paras = re.split(r\"\\n\\s*\\n\", text.strip())\n","    chunks, current = [], \"\"\n","    for p in paras:\n","        if not p.strip():\n","            continue\n","        if len((current + \"\\n\\n\" + p).split()) > max_words:\n","            if current.strip():\n","                chunks.append(current.strip())\n","            current = p\n","        else:\n","            current = (current + \"\\n\\n\" + p).strip()\n","    if current.strip():\n","        chunks.append(current.strip())\n","    return chunks\n","\n","def _summarize(text, max_length, min_length, do_sample, temperature, top_p):\n","    \"\"\"\n","    Summarize, chunking if needed. Returns summary text only.\n","    \"\"\"\n","    if _SUMMARIZER is None:\n","        raise gr.Error(\"Please load a model first (top-left) before summarizing.\")\n","    if not text or not text.strip():\n","        raise gr.Error(\"Please paste some input text.\")\n","\n","    pieces = _chunk_text_words(text, max_words=800)\n","    outputs = []\n","    for piece in pieces:\n","        result = _SUMMARIZER(\n","            piece,\n","            max_length=int(max_length),\n","            min_length=int(min_length),\n","            do_sample=bool(do_sample),\n","            temperature=float(temperature),\n","            top_p=float(top_p),\n","            truncation=True,\n","        )\n","        summary_piece = result[0][\"summary_text\"].strip()\n","        outputs.append(summary_piece)\n","    return \"\\n\\n\".join(outputs).strip()\n","\n","def _tts(summary_text, lang=\"en\"):\n","    \"\"\"\n","    Convert summary to speech (MP3) using gTTS. Returns file path.\n","    \"\"\"\n","    if not summary_text or not summary_text.strip():\n","        raise gr.Error(\"Nothing to read. Please summarize first.\")\n","    fn = Path(tempfile.gettempdir()) / f\"summary_{uuid.uuid4().hex}.mp3\"\n","    tts = gTTS(summary_text, lang=lang)\n","    tts.save(str(fn))\n","    return str(fn)\n","\n","def _export(original_text, summary_text, model_id, audio_path):\n","    \"\"\"\n","    Export a ZIP containing summary.txt, meta.json, and the audio MP3 (if present).\n","    Returns path to the ZIP.\n","    \"\"\"\n","    if not summary_text or not summary_text.strip():\n","        raise gr.Error(\"No summary to export. Please summarize first.\")\n","\n","    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    base = Path(tempfile.gettempdir()) / f\"summarization_{ts}_{uuid.uuid4().hex[:6]}\"\n","    base.parent.mkdir(parents=True, exist_ok=True)\n","\n","    txt_path = base.with_suffix(\".txt\")\n","    meta_path = base.with_suffix(\".json\")\n","    zip_path = base.with_suffix(\".zip\")\n","\n","    meta = {\n","        \"timestamp\": ts,\n","        \"model_id\": model_id or _CURRENT_MODEL_ID,\n","        \"original_chars\": len(original_text or \"\"),\n","        \"summary_chars\": len(summary_text or \"\"),\n","    }\n","\n","    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(summary_text)\n","\n","    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(meta, f, ensure_ascii=False, indent=2)\n","\n","    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n","        z.write(txt_path, arcname=\"summary.txt\")\n","        z.write(meta_path, arcname=\"meta.json\")\n","        if audio_path and os.path.exists(audio_path):\n","            z.write(audio_path, arcname=\"summary_audio.mp3\")\n","\n","    return str(zip_path)\n","\n","# ---- Minimal CSS vars for a clean light/dark toggle (no reload) ----\n","CUSTOM_CSS = \"\"\"\n",":root {\n","  --app-radius: 14px;\n","  --app-pad: 14px;\n","}\n",".gradio-container { max-width: 1040px !important; margin: auto !important; }\n","\n",".dark, .dark * {\n","  /* Dark mode overrides */\n","  --block-background-fill: #0b0f19 !important;\n","  --body-background-fill: #0b0f19 !important;\n","  --body-text-color: #e6e7eb !important;\n","  --link-text-color: #a5b4fc !important;\n","  --button-primary-background-fill: #1f2937 !important;\n","  --button-primary-text-color: #e6e7eb !important;\n","  --input-background-fill: #111827 !important;\n","  --input-border-color: #374151 !important;\n","  --border-color-primary: #374151 !important;\n","}\n",".dark .gradio-container, .dark .gr-block, .dark .gr-panel, .dark .gradio-container * {\n","  color: var(--body-text-color) !important;\n","}\n",".dark textarea, .dark input, .dark .tokenizer, .dark .wrap, .dark .form, .dark .prose {\n","  background: var(--input-background-fill) !important; color: var(--body-text-color) !important;\n","}\n",".card {\n","  border-radius: var(--app-radius);\n","  padding: var(--app-pad);\n","  border: 1px solid var(--border-color-primary);\n","  background: var(--block-background-fill);\n","}\n","\"\"\"\n","\n","# ---- Build UI ----\n","with gr.Blocks(title=\"HF Summarizer + TTS\", css=CUSTOM_CSS, fill_height=True) as demo:\n","    gr.Markdown(\"## üîé Text Summarization (Hugging Face) ¬∑ üîä TTS ¬∑ üíæ Export ¬∑ üåó Dark/Light\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=3):\n","            model_id = gr.Textbox(\n","                label=\"Hugging Face Model ID\",\n","                value=\"facebook/bart-large-cnn\",\n","                placeholder=\"e.g. facebook/bart-large-cnn, google/pegasus-xsum, philschmid/bart-large-cnn-samsum\"\n","            )\n","        with gr.Column(scale=1):\n","            load_btn = gr.Button(\"Load / Reload Model\", variant=\"primary\")\n","            model_status = gr.Markdown(\"‚ÑπÔ∏è No model loaded yet.\")\n","        with gr.Column(scale=1, min_width=160):\n","            dark_toggle = gr.Checkbox(label=\"üåó Dark Mode\", value=False, interactive=True)\n","\n","    with gr.Row():\n","        with gr.Column():\n","            gr.Markdown(\"#### Input\")\n","            input_text = gr.Textbox(lines=12, placeholder=\"Paste or type the text you want summarized...\", container=True)\n","            with gr.Row():\n","                min_len = gr.Slider(10, 200, value=32, step=1, label=\"min_length\")\n","                max_len = gr.Slider(50, 512, value=128, step=1, label=\"max_length\")\n","            with gr.Row():\n","                do_sample = gr.Checkbox(value=False, label=\"do_sample\")\n","                temperature = gr.Slider(0.1, 2.0, value=1.0, step=0.1, label=\"temperature\")\n","                top_p = gr.Slider(0.1, 1.0, value=1.0, step=0.05, label=\"top_p\")\n","            run_btn = gr.Button(\"‚ñ∂Ô∏è Summarize\", variant=\"primary\")\n","\n","        with gr.Column():\n","            gr.Markdown(\"#### Output\")\n","            summary_out = gr.Textbox(lines=12, label=\"Summary\", interactive=False)\n","            audio_out = gr.Audio(label=\"Summary Audio (TTS)\", autoplay=False)\n","            with gr.Row():\n","                speak_btn = gr.Button(\"üîä Read Summary\")\n","                export_btn = gr.Button(\"üíæ Export Summary + Audio (ZIP)\")\n","            export_file = gr.File(label=\"Download Export (ZIP)\", file_types=[\".zip\"])\n","\n","    # Keep last audio path in state so export can include it\n","    audio_state = gr.State(\"\")\n","\n","    # --- Wire events ---\n","    load_btn.click(\n","        fn=_load_model,\n","        inputs=[model_id],\n","        outputs=[model_status, gr.Textbox(visible=False)],\n","        api_name=\"load_model\"\n","    )\n","\n","    def _do_all(text, max_length, min_length, do_sample, temperature, top_p, current_model):\n","        summary = _summarize(text, max_length, min_length, do_sample, temperature, top_p)\n","        # Create audio immediately after summarization for a smoother UX\n","        audio = _tts(summary, lang=\"en\")\n","        return summary, audio, audio\n","\n","    run_btn.click(\n","        fn=_do_all,\n","        inputs=[input_text, max_len, min_len, do_sample, temperature, top_p, model_id],\n","        outputs=[summary_out, audio_out, audio_state],\n","        api_name=\"summarize\"\n","    )\n","\n","    speak_btn.click(\n","        fn=lambda s: _tts(s, lang=\"en\"),\n","        inputs=[summary_out],\n","        outputs=[audio_out],\n","        api_name=\"tts\"\n","    )\n","\n","    export_btn.click(\n","        fn=_export,\n","        inputs=[input_text, summary_out, model_id, audio_state],\n","        outputs=[export_file],\n","        api_name=\"export\"\n","    )\n","\n","    # Dark/Light toggle via simple JS; no reload needed\n","    # (Just flips a 'dark' class on <html>)\n","    dark_toggle.change(\n","        fn=lambda x: None,  # no Python work\n","        inputs=[dark_toggle],\n","        outputs=[],\n","        js=\"\"\"\n","            (checked) => {\n","              const root = document.documentElement;\n","              if (checked) root.classList.add('dark');\n","              else root.classList.remove('dark');\n","            }\n","        \"\"\",\n","    )\n","\n","demo.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"NLMAHIM0y8ZX","executionInfo":{"status":"ok","timestamp":1761671389262,"user_tz":-330,"elapsed":19104,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"04d78536-c576-4297-8885-c3f407e7fded"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://34da67ef173cd8ee28.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://34da67ef173cd8ee28.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":[],"metadata":{"id":"tWpSsrJ1i3hC"}},{"cell_type":"markdown","source":[],"metadata":{"id":"LaVsPDl7i3Oc"}}]}